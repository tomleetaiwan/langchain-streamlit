#  åŸ·è¡Œæ–¹å¼ streamlit run main.py

import os
import json
import streamlit as st
import pandas as pd
import sqlalchemy as sa
from sqlalchemy.engine import URL
from sqlalchemy import create_engine
from streamlit_chat import message
from dotenv import load_dotenv
from langchain.embeddings import OpenAIEmbeddings
from langchain import LLMChain,PromptTemplate
from langchain.chat_models import AzureChatOpenAI
from langchain.document_loaders import WikipediaLoader
from langchain.llms import OpenAI
from langchain.schema import (
    SystemMessage,
    HumanMessage,
    AIMessage
)

# è¨­å®šå‘¼å« OpenAI API æ‰€éœ€é€£ç·šè³‡è¨Š
chat_model = 'gpt-35-turbo'
embeddings_model = 'text-embedding-ada-002'

# è¼‰å…¥ Azure OpenAI Service API ç›¸é—œè³‡è¨Š
load_dotenv()

# å»ºç«‹ Azure OpenAI Chat èˆ‡ Embeddings é¡åˆ¥çš„å¯¦ä¾‹
chat = AzureChatOpenAI(deployment_name=chat_model,model_name=chat_model,temperature=0, max_tokens=2000)
embeddings = OpenAIEmbeddings(deployment=embeddings_model, chunk_size = 16)

# å»ºç«‹ Azure SQL Database é€£ç·š
connection_string = os.getenv("SQL_CONNECTION_STRING")
connection_url = URL.create("mssql+pyodbc", query={"odbc_connect": connection_string})
sql_engine = create_engine(connection_url,connect_args={"timeout": 120})

def init():
    # è¨­å®š streamlit é¦–é 
    st.set_page_config(
        page_title="Azure OpenAI Service ChatGPT å°è©±æ©Ÿå™¨äºº",
        page_icon="ğŸ¤–"
    )

def question_filter(input_str):
    prompt = PromptTemplate(input_variables=["prompt_str"],template="äº‹å¯¦:{prompt_str}\n" \
                                             "äº‹å¯¦ä¸­é€™å¥è©±çš„æ„åœ–æ˜¯æŸ¥è©¢å—? å¦‚æœæ˜¯ä¸¦æ­¤å•é¡Œå¯ä»¥åœ¨ Wikipedia ä¸ŠæŸ¥å¾—åˆ°è«‹å›ç­”ä¸€å€‹å­—æ¯ [Y]\n" \
                                             "äº‹å¯¦ä¸­é€™å¥è©±çš„æ„åœ–æ˜¯æŸ¥è©¢å—? å¦‚æœæ˜¯ä¸¦æ­¤å•é¡Œç„¡æ³•åœ¨ Wikipedia ä¸ŠæŸ¥å¾—åˆ°è«‹å›ç­”ä¸€å€‹å­—æ¯ [N]\n" \
                                             "å¦‚æœäº‹å¯¦é€™å¥è©±çš„æ„åœ–ä¸æ˜¯æŸ¥è©¢ï¼Œè«‹å›ç­”ä¸€å€‹å­—æ¯ [C]\n")
    # å°‡ AzureChatOpenAI ä»¥ LLMChain æ–¹å¼ä½¿ç”¨
    chain = LLMChain(llm=chat,prompt=prompt)
    response = chain.run(input_str)
    return(response)

def get_query_english_keyword(input_str):
    prompt = PromptTemplate(input_variables=["prompt_str"],template="äº‹å¯¦:{prompt_str}\n" \
                                            "å°‡äº‹å¯¦è½‰æ›ç‚ºä¸€å¥åŒ…å«é—œéµå­—çš„è‹±æ–‡\n" \
                                            "English Fact:")
    # å°‡ AzureChatOpenAI ä»¥ LLMChain æ–¹å¼ä½¿ç”¨
    chain = LLMChain(llm=chat,prompt=prompt)
    response = chain.run(input_str)
    return(response)

def embeddings_query(input_str):
    # æŸ¥è©¢æ–‡å­—è½‰æ›ç‚º OpenAI Embeddings å‘é‡å€¼ï¼Œå†è½‰ç‚º JSON æ ¼å¼å­—ä¸²
    response = embeddings.embed_query(input_str)
    json_str = json.dumps(response)
    # æŸ¥å‡ºæœ€æ–°ç›¸é—œçš„ 3 å€‹æ¢ç›®
    sql = "select top 3 cosine_distance,title,url from dbo.SimilarContentArticles ('"+ json_str + "') as r order by cosine_distance desc"
    # æŸ¥è©¢çµæœç½®æ–¼ DataFrame    
    with sql_engine.begin() as conn:
        output_df = pd.read_sql_query(sa.text(sql), conn)        
    return (output_df)

def answer_summary (input_str,title):
    # å–å¾— Simple English Wikipedia çš„ç¶²é å…§å®¹
    docs = WikipediaLoader(query=title, load_max_docs=1).load()
    html_body = docs[0].page_content[:2000]  

    # å°‡ç¶²é å…§å®¹è½‰æ›ç‚ºæ‘˜è¦
    prompt = PromptTemplate(input_variables=["question_str","html_str"],template="äº‹å¯¦:{question_str}\n" \
                                            "HTML:{html_str}\n" \
                                            "è§£æ HTML çš„å…§å®¹ï¼Œä¾æ“šé€™äº›å…§å®¹ä»¥ä¸€ç™¾å­—æ‘˜è¦çš„æ–¹å¼ï¼Œç”¨ç¹é«”ä¸­æ–‡å›ç­”äº‹å¯¦å…§æå‡ºçš„å•é¡Œï¼Œ" \
                                            "å¦‚æœ HTML è§£æå‡ºä¾†çš„å…§å®¹ç„¡æ³•å›ç­”äº‹å¯¦å…§çš„å•é¡Œï¼Œå‰‡å›è¦† 'å¾ˆæŠ±æ­‰æˆ‘ä¸çŸ¥é“ç­”æ¡ˆï¼Œé€™æ˜¯æœ€æ¥è¿‘çš„æ¢ç›®'" \
                                            "å›è¦†:")

    # å°‡ AzureChatOpenAI ä»¥ LLMChain æ–¹å¼ä½¿ç”¨
    chain = LLMChain(llm=chat,prompt=prompt)
    response = chain.run(question_str=input_str,html_str=html_body)
    return (response)

def main():
    init()

    # èµ·å§‹ messages session
    if "messages" not in st.session_state:
        st.session_state.messages = [
            SystemMessage(content='ä½ æ˜¯ä¸€å€‹é‡å° Wikipeida å…§å®¹æŸ¥è©¢çš„ç¹é«”ä¸­æ–‡çš„å°è©±æ©Ÿå™¨äººï¼Œä»¥æ´»æ½‘é¢¨æ ¼å›å•é¡Œ')
        ]
        st.session_state.messages.append(AIMessage(content="æ‚¨å¥½ã€‚æˆ‘æ˜¯ä¸€å€‹å¯ä»¥é‹ç”¨ OpenAI Embeddings æ¯”å°æŸ¥è©¢ Simple English Wikipeida çš„å°è©±æ©Ÿå™¨äººã€‚"))

    st.header("Azure OpenAI Service æ‰“é€ ä¹‹ ğŸ¤–")

    # è™•ç†å´é‚Šç”¨æˆ¶è¼¸å…¥
    with st.sidebar:
        user_input = st.text_input("è¼¸å…¥è¨Šæ¯: ", key="user_input")

        # è™•ç†ç”¨æˆ¶è¼¸å…¥
        if user_input: 
            st.session_state.messages.append(HumanMessage(content=user_input))
            with st.spinner("æ€è€ƒä¸­..."):
                # åˆ¤æ–·ç”¨æˆ¶è¼¸å…¥å…§å®¹é¡å‹
                question_type = question_filter(user_input)
                if question_type == 'Y': 
                    # å°‡ç”¨æˆ¶è¼¸å…¥æ–‡å­—è½‰æ›ç‚ºè‹±æ–‡ï¼Œä»¥å¢åŠ æŸ¥è©¢æº–ç¢ºåº¦
                    english_keyword = get_query_english_keyword(user_input) 
                    # å°‡è‹±æ–‡è½‰æ›ç‚º OpenAI Embeddings å‘é‡å€¼ï¼Œå†è½‰ç‚º JSON æ ¼å¼å­—ä¸²å° SQL Server é€²è¡Œé¤˜æ‡¸é€²è¡Œé¤˜å¼¦ç›¸ä¼¼åº¦è¨ˆç®—æ¯”å°                  
                    respons_str = 'é€™æ˜¯ç”¨ OpenAI æ‰€æä¾›çš„ Simple English Wikipeida Embeddings è³‡æ–™ï¼Œæ¯”å°å‡ºä¾†æœ€ç›¸é—œçš„ä¸‰å€‹æ¢ç›®ï¼Œ\n'
                    respone_df = embeddings_query(english_keyword)
                    # é¡¯ç¤ºå‘é‡è¿‘ä¼¼æŸ¥è©¢çµæœæ–¼å·¦å´çª—æ ¼
                    st.markdown("æ¯”å°å…§å®¹: "+ english_keyword)
                    st.dataframe(respone_df)
                    # å–å¾—ç¬¬ä¸€å€‹æ¢ç›®çš„æ¨™é¡Œï¼Œåšå…§å®¹ç‚ºå›è¦†æ‘˜è¦
                    respons_str = respons_str + answer_summary (english_keyword,respone_df.iloc[0]['title']) + "\n\n è³‡æ–™ä¾†æº: \n"
                    # å°‡æœ€æ¥è¿‘çš„ä¸‰å€‹æ¢ç›®çš„ç¶²å€åŠ å…¥åƒè€ƒè³‡æ–™
                    for index, row in respone_df.iterrows():
                        respons_str = respons_str + str(index+1)+". [*" + row['title'] + "*](" +  row['url'] + ") \n"                        
                    st.session_state.messages.append(AIMessage(content=respons_str))
                else:
                    if question_type == 'C':
                        # éæŸ¥è©¢é¡å•é¡Œï¼Œè®“ ChatGPT æ¨¡å‹è‡ªç”±å›ç­”
                        response = chat(st.session_state.messages)                        
                        # å°‡å›è¦†è³‡æ–™åŠ å…¥å°è©±æ­·å²ç´€éŒ„ 
                        st.session_state.messages.append(AIMessage(content=response.content))
                    else:
                        # è™•ç†ç„¡æ³•å›è¦†ä¹‹æŸ¥è©¢å•é¡Œ 
                        st.session_state.messages.append(AIMessage(content="æŠ±æ­‰ï¼Œæˆ‘ä¸çŸ¥é“ ..."))
                
    # é¡¯ç¤ºå°è©±æ­·å²ç´€éŒ„
    messages = st.session_state.get('messages', [])
    for i, msg in enumerate(messages[1:]):
        if i % 2 == 0:  
            # ç”¨æˆ¶è¼¸å…¥          
            with st.chat_message("user"):
                st.markdown(msg.content)
            
        else:            
            # æ©Ÿå™¨äººå›è¦†
            with st.chat_message("assistant"):
                st.markdown(msg.content)
         

if __name__ == '__main__':
    main()